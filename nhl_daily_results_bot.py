#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
NHL Daily Results ‚Üí Telegram (sports.ru scraper)
- –ë–µ—Ä—ë—Ç —Å https://www.sports.ru/hockey/tournament/nhl/calendar/ —Å–ø–∏—Å–æ–∫ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö –º–∞—Ç—á–µ–π –∑–∞ –Ω—É–∂–Ω—É—é –¥–∞—Ç—É
- –ó–∞—Ö–æ–¥–∏—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞–∂–¥–æ–≥–æ –º–∞—Ç—á–∞ –∏ –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ—Ç –ª–µ–Ω—Ç—É –≥–æ–ª–æ–≤ (–∫–æ–º–∞–Ω–¥–∞ ‚Üí [–≤—Ä–µ–º—è, –∞–≤—Ç–æ—Ä, –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—ã])
- –°–æ–±–∏—Ä–∞–µ—Ç –ø–æ—Å—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ –∏–∑ –¢–ó –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ —Ç–µ–ª–µ–≥—Ä–∞–º-–∫–∞–Ω–∞–ª
"""

import os
import sys
import re
import math
import time
import textwrap
from html import escape
from urllib.parse import urljoin

from datetime import datetime, date
from zoneinfo import ZoneInfo

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup

# ------ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è ------
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
CHAT_ID   = os.getenv("TELEGRAM_CHAT_ID", "").strip()

BASE = "https://www.sports.ru"
CALENDAR_URL = f"{BASE}/hockey/tournament/nhl/calendar/"

# ------ HTTP —Å —Ä–µ—Ç—Ä–∞—è–º–∏ ------
def make_session():
    s = requests.Session()
    retries = Retry(
        total=6, connect=6, read=6,
        backoff_factor=0.7,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "POST"],
        raise_on_status=False,
    )
    s.mount("https://", HTTPAdapter(max_retries=retries))
    s.headers.update({
        "User-Agent": "NHL-DailyResultsBot/1.0 (+https://sports.ru; telegram @nhl_results)",
        "Accept-Language": "ru-RU,ru;q=0.9,en;q=0.6",
    })
    return s

S = make_session()

# ------ –≤—Å–ø–æ–º–æ–≥–∞–ª–∫–∏ ------
RU_MONTHS = {
    1: "—è–Ω–≤–∞—Ä—è", 2: "—Ñ–µ–≤—Ä–∞–ª—è", 3: "–º–∞—Ä—Ç–∞", 4: "–∞–ø—Ä–µ–ª—è",
    5: "–º–∞—è", 6: "–∏—é–Ω—è", 7: "–∏—é–ª—è", 8: "–∞–≤–≥—É—Å—Ç–∞",
    9: "—Å–µ–Ω—Ç—è–±—Ä—è", 10: "–æ–∫—Ç—è–±—Ä—è", 11: "–Ω–æ—è–±—Ä—è", 12: "–¥–µ–∫–∞–±—Ä—è",
}

def ru_date(d: date) -> str:
    return f"{d.day} {RU_MONTHS[d.month]}"

def ru_plural(n: int, forms: tuple[str, str, str]) -> str:
    # —Ñ–æ—Ä–º—ã: ("–º–∞—Ç—á", "–º–∞—Ç—á–∞", "–º–∞—Ç—á–µ–π")
    n = abs(n) % 100
    n1 = n % 10
    if 11 <= n <= 19: return forms[2]
    if 2 <= n1 <= 4:  return forms[1]
    if n1 == 1:      return forms[0]
    return forms[2]

TEAM_EMOJI = {
    "–ê–Ω–∞—Ö–∞–π–º": "ü¶Ü", "–ê—Ä–∏–∑–æ–Ω–∞": "ü§†", "–ë–æ—Å—Ç–æ–Ω": "üêª", "–ë–∞—Ñ—Ñ–∞–ª–æ": "ü¶¨",
    "–ö–∞–ª–≥–∞—Ä–∏": "üî•", "–ö–∞—Ä–æ–ª–∏–Ω–∞": "üå™Ô∏è", "–ö–æ–ª–æ—Ä–∞–¥–æ": "‚õ∞Ô∏è", "–ö–æ–ª–∞–º–±—É—Å": "üí£",
    "–î–∞–ª–ª–∞—Å": "‚≠ê", "–î–µ—Ç—Ä–æ–π—Ç": "üöó", "–≠–¥–º–æ–Ω—Ç–æ–Ω": "üõ¢Ô∏è", "–§–ª–æ—Ä–∏–¥–∞": "üêÜ",
    "–õ–æ—Å-–ê–Ω–¥–∂–µ–ª–µ—Å": "üé•", "–ú–∏–Ω–Ω–µ—Å–æ—Ç–∞": "üå≤", "–ú–æ–Ω—Ä–µ–∞–ª—å": "üèí", "–ù—ç—à–≤–∏–ª–ª": "üé∏",
    "–ù—å—é-–î–∂–µ—Ä—Å–∏": "üòà", "–ê–π–ª–µ–Ω–¥–µ—Ä—Å": "üèùÔ∏è", "–†–µ–π–Ω–¥–∂–µ—Ä—Å": "üóΩ", "–û—Ç—Ç–∞–≤–∞": "üèõÔ∏è",
    "–§–∏–ª–∞–¥–µ–ª—å—Ñ–∏—è": "üüß", "–ü–∏—Ç—Ç—Å–±—É—Ä–≥": "üêß", "–°–∞–Ω-–•–æ—Å–µ": "ü¶à", "–°–∏—ç—Ç–ª": "ü¶ë",
    "–°–µ–Ω—Ç-–õ—É–∏—Å": "üéº", "–¢–∞–º–ø–∞-–ë—ç–π": "‚ö°", "–¢–æ—Ä–æ–Ω—Ç–æ": "üçÅ", "–í–∞–Ω–∫—É–≤–µ—Ä": "üêã",
    "–í–µ–≥–∞—Å": "üé∞", "–í–∞—à–∏–Ω–≥—Ç–æ–Ω": "ü¶Ö", "–í–∏–Ω–Ω–∏–ø–µ–≥": "‚úàÔ∏è", "–Æ—Ç–∞": "‚õ∞Ô∏è",
}

def emj(team: str) -> str:
    for k, v in TEAM_EMOJI.items():
        if k.lower() in team.lower():
            return v
    return "üèí"

def get_london_today():
    return datetime.now(ZoneInfo("Europe/London")).date()

def log(*a):
    print(*a, file=sys.stderr)

# ------ –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞–ª–µ–Ω–¥–∞—Ä—è –∑–∞ –Ω—É–∂–Ω—É—é –¥–∞—Ç—É ------
def fetch_calendar_html() -> str:
    r = S.get(CALENDAR_URL, timeout=30)
    r.raise_for_status()
    return r.text

def parse_calendar_for_date(html: str, target: date) -> list[dict]:
    """
    –ò—â–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã, –≥–¥–µ –¥–∞—Ç–∞ == target –∏ —Å—á—ë—Ç —É–∂–µ –Ω–µ '- : -'
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫: {home, away, score, match_url}
    """
    soup = BeautifulSoup(html, "html.parser")
    rows = soup.select("table tr")
    target_str = target.strftime("%d.%m.%Y")

    out = []
    for tr in rows:
        tds = tr.find_all("td")
        if len(tds) < 4:
            continue
        dt_text = " ".join(tds[0].get_text(" ", strip=True).split())
        if target_str not in dt_text:
            continue

        score_cell = tds[2]
        score_text = score_cell.get_text(" ", strip=True)
        if "-" in score_text and ":" in score_text and score_text.strip().startswith("-"):
            # –µ—â—ë –Ω–µ —Å—ã–≥—Ä–∞–Ω–æ: "- : -"
            continue

        a_score = score_cell.find("a")
        if not a_score or "/hockey/match/" not in (a_score.get("href") or ""):
            continue

        home_team = tds[1].get_text(" ", strip=True)
        away_team = tds[3].get_text(" ", strip=True)
        match_url = urljoin(BASE, a_score["href"])

        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø—Ä–æ–±–µ–ª—ã –∏ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏ —Å—á—ë—Ç–∞
        score_text = score_text.replace(" ", "").replace(":", ":")
        out.append({
            "home": home_team,
            "away": away_team,
            "score": score_text,   # –≤–∏–¥–∞ 5:3, 4:5–±, 2:3–æ—Ç –∏ —Ç.–ø.
            "url": match_url
        })

    return out

# ------ –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–∞—Ç—á–∞ (–ª–µ–Ω—Ç–∞ –≥–æ–ª–æ–≤ –≤ –≤–µ—Ä—Ö–Ω–µ–º –±–ª–æ–∫–µ) ------
GOAL_LINE_RE = re.compile(
    r"^\*\s*(?P<time>\d{1,2}:\d{2})\s*(?P<scorer>[^(,\n]+?)\s*(?:\((?P<ast>[^)]+)\))?\s*$",
    re.M
)

def extract_goal_block(text: str, team_name: str) -> str | None:
    """
    –í–Ω—É—Ç—Ä–∏ –ø–ª–æ—Å–∫–æ–≥–æ .get_text() —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–∞—Ç—á–µ–π –Ω–∞ sports.ru
    –Ω–∞–≤–µ—Ä—Ö—É –∏–¥—ë—Ç:
      <–ö–æ–º–∞–Ω–¥–∞ A>
        * 20:40 –•—ç–º–∏–ª—Ç–æ–Ω (–ú–µ—Ä—Å–µ—Ä, –•–∏—à–∏—Ä)
        * ...
      <–ö–æ–º–∞–Ω–¥–∞ B>
        * 2:25 –≠–∫–ª—É–Ω–¥ (–°–µ–ª–µ–±—Ä–∏–Ω–∏)
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –±–ª–æ–∫ –ø–æ—Å–ª–µ –ª–µ–π–±–ª–∞ team_name –¥–æ —Å–ª–µ–¥—É—é—â–µ–π –∫–æ–º–∞–Ω–¥—ã/–∑–∞–≥–æ–ª–æ–≤–∫–∞.
    """
    # –ò—â–µ–º –Ω–∞—á–∞–ª–æ –±–ª–æ–∫–∞
    start = text.find(f"\n{team_name}\n")
    if start == -1:
        return None
    # –°–ª–µ–¥—É—é—â–∏–π –∑–∞–≥–æ–ª–æ–≤–æ–∫ ‚Äî —ç—Ç–æ –ª–∏–±–æ –∏–º—è –¥—Ä—É–≥–æ–π –∫–æ–º–∞–Ω–¥—ã, –ª–∏–±–æ "## " (–Ω–æ–≤—ã–π —Ä–∞–∑–¥–µ–ª)
    rest = text[start + len(team_name) + 2:]
    # –æ–±—Ä–µ–∂–µ–º –ø–æ –±–ª–∏–∂–∞–π—à–µ–º—É "## " (–Ω–∞–ø—Ä–∏–º–µ—Ä, "## –¢—Ä–∞–Ω—Å–ª—è—Ü–∏—è")
    cut = rest.find("\n##")
    if cut != -1:
        rest = rest[:cut]
    return rest

def parse_team_goals_from_block(block: str) -> list[dict]:
    goals = []
    for m in GOAL_LINE_RE.finditer(block):
        t = m.group("time")
        scorer = " ".join(m.group("scorer").split())
        ast = m.group("ast") or ""
        ast = " ".join(ast.split())
        goals.append({"time": t, "scorer": scorer, "assists": ast})
    return goals

def parse_match_goals(match_url: str, home: str, away: str) -> list[dict]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≥–æ–ª–æ–≤ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –∫–æ–º–∞–Ω–¥–µ:
      [{"team":"home"/"away","sec":int,"min":int,"scorer":str,"assists":str}]
    """
    r = S.get(match_url, timeout=30)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")
    text = soup.get_text("\n")

    home_block = extract_goal_block(text, home) or ""
    away_block = extract_goal_block(text, away) or ""
    home_goals = parse_team_goals_from_block(home_block)
    away_goals = parse_team_goals_from_block(away_block)

    # –≤ –±–ª–æ–∫–∞—Ö –º–æ–≥–ª–∏ –ø–æ–ø–∞—Å—Ç—å —á—É–∂–∏–µ —Å—Ç—Ä–æ–∫–∏ –ø—Ä–∏ –Ω–µ–∏–¥–µ–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–µ ‚Äî –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –Ω–∞–ª–∏—á–∏—é –≤—Ä–µ–º–µ–Ω–∏
    def t2sec(ts: str) -> int:
        m, s = ts.split(":")
        return int(m) * 60 + int(s)

    events = []
    for g in home_goals:
        sec = t2sec(g["time"])
        events.append({"team": "home", "sec": sec, "min": int(g["time"].split(":")[0]),
                       "scorer": g["scorer"], "assists": g["assists"]})
    for g in away_goals:
        sec = t2sec(g["time"])
        events.append({"team": "away", "sec": sec, "min": int(g["time"].split(":")[0]),
                       "scorer": g["scorer"], "assists": g["assists"]})

    # –•—Ä–æ–Ω–æ–ª–æ–≥–∏—è
    events.sort(key=lambda x: x["sec"])
    return events

# ------ —Å–±–æ—Ä–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è ------
def build_post(target_day: date) -> str:
    cal_html = fetch_calendar_html()
    matches = parse_calendar_for_date(cal_html, target_day)

    title = f"üóì –†–µ–≥—É–ª—è—Ä–Ω—ã–π —á–µ–º–ø–∏–æ–Ω–∞—Ç –ù–•–õ ‚Ä¢ {ru_date(target_day)} ‚Ä¢ {len(matches)} {ru_plural(len(matches), ('–º–∞—Ç—á', '–º–∞—Ç—á–∞', '–º–∞—Ç—á–µ–π'))}\n\n"
    title += "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞–¥—ë–∂–Ω–æ —Å–ø—Ä—è—Ç–∞–Ω—ã üëá\n\n‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n\n"

    chunks = [title]

    for i, m in enumerate(matches, 1):
        home, away, score = m["home"], m["away"], m["score"]
        # —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å—á—ë—Ç –ø–æ —á–∏—Å–ª–∞–º –¥–ª—è —à–∞–ø–∫–∏
        m_sc = re.match(r"^\s*(\d+)\s*:\s*(\d+)", score)
        hs, as_ = ("?", "?")
        if m_sc:
            hs, as_ = m_sc.group(1), m_sc.group(2)

        # –ª–µ–Ω—Ç–∞ –≥–æ–ª–æ–≤
        lines = []
        try:
            events = parse_match_goals(m["url"], home, away)
            h_go, a_go = 0, 0
            for ev in events:
                if ev["team"] == "home":
                    h_go += 1
                else:
                    a_go += 1
                assists = f" ({ev['assists']})" if ev["assists"] else ""
                lines.append(f"{h_go}:{a_go} ‚Äì {ev['min']} {ev['scorer']}{assists}")
        except Exception as e:
            log(f"[WARN] goals parse failed for {home} vs {away}: {e}")
            lines.append("‚Äî –ø–æ–¥—Ä–æ–±–Ω–∞—è –∑–∞–ø–∏—Å—å –≥–æ–ª–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")

        block = (
            f"{emj(home)} ¬´{home}¬ª: {hs}\n"
            f"{emj(away)} ¬´{away}¬ª: {as_}\n\n" +
            "\n".join(lines)
        )

        chunks.append(block.rstrip() + ("\n\n" if i < len(matches) else ""))

    return "".join(chunks).strip()

# ------ –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram (—Å –¥–µ–ª–µ–Ω–∏–µ–º –Ω–∞ —á–∞—Å—Ç–∏, —á—Ç–æ–±—ã –Ω–µ —É–ø–µ—Ä–µ—Ç—å—Å—è –≤ 4096 —Å–∏–º–≤.) ------
def tg_send(text: str):
    if not (BOT_TOKEN and CHAT_ID):
        raise RuntimeError("TELEGRAM_BOT_TOKEN / TELEGRAM_CHAT_ID –Ω–µ –∑–∞–¥–∞–Ω—ã")

    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    # –¥–µ–ª–∏–º –ø–æ ~3500, —Å—Ç–∞—Ä–∞—è—Å—å —Ä–µ–∑–∞—Ç—å –ø–æ –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–µ
    MAX = 3500
    parts = []
    t = text
    while t:
        if len(t) <= MAX:
            parts.append(t)
            break
        cut = t.rfind("\n\n", 0, MAX)
        if cut == -1:
            cut = MAX
        parts.append(t[:cut])
        t = t[cut:].lstrip()

    for part in parts:
        resp = S.post(url, json={
            "chat_id": CHAT_ID,
            "text": part,
            "disable_web_page_preview": True,
        }, timeout=30)
        if resp.status_code != 200:
            raise RuntimeError(f"Telegram error {resp.status_code}: {resp.text}")
        # –º–∞–ª–µ–Ω—å–∫–∞—è –ø–∞—É–∑–∞, —á—Ç–æ–±—ã –Ω–µ —Ç—Ä–æ—Ç—Ç–ª–∏–ª–æ
        time.sleep(0.6)

# ------ main ------
if __name__ == "__main__":
    try:
        # –õ–æ–≥–∏–∫–∞ ¬´–ø–æ—Å–ª–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –º–∞—Ç—á–∞ –∏–≥—Ä–æ–≤–æ–≥–æ –¥–Ω—è¬ª: –∑–∞–ø—É—Å–∫–∞–µ–º —É—Ç—Ä–æ–º –ø–æ –õ–æ–Ω–¥–æ–Ω—É –∏ –±–µ—Ä—ë–º "—Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é" –¥–∞—Ç—É.
        # –ö–∞–ª–µ–Ω–¥–∞—Ä—å sports.ru —Å–æ–¥–µ—Ä–∂–∏—Ç –≤ —Ç–µ—á–µ–Ω–∏–µ –¥–Ω—è –∏ —Å—ã–≥—Ä–∞–Ω–Ω—ã–µ, –∏ –±—É–¥—É—â–∏–µ –º–∞—Ç—á–∏ —Ç–æ–π –∂–µ –¥–∞—Ç—ã.
        # –ú—ã –≤–∫–ª—é—á–∞–µ–º –¢–û–õ–¨–ö–û —Ç–µ —Å—Ç—Ä–æ–∫–∏, –≥–¥–µ —Å—á—ë—Ç —É–∂–µ –∑–∞–¥–∞–Ω (–Ω–µ "- : -") ‚Äî —ç—Ç–æ –∏ –µ—Å—Ç—å –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ –∏–≥—Ä—ã.
        target = get_london_today()
        post = build_post(target)
        tg_send(post)
        print("OK")
    except Exception as e:
        print("ERROR:", repr(e), file=sys.stderr)
        sys.exit(1)
