#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
NHL Daily Results ‚Üí Telegram (sports.ru scraper)
- –ë–µ—Ä—ë—Ç —Å https://www.sports.ru/hockey/tournament/nhl/calendar/ —Å–ø–∏—Å–æ–∫ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö –º–∞—Ç—á–µ–π –∑–∞ –Ω—É–∂–Ω—É—é –¥–∞—Ç—É
- –ó–∞—Ö–æ–¥–∏—Ç –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –∫–∞–∂–¥–æ–≥–æ –º–∞—Ç—á–∞ –∏ –≤—ã—Ç–∞—Å–∫–∏–≤–∞–µ—Ç –ª–µ–Ω—Ç—É –≥–æ–ª–æ–≤ (–∫–æ–º–∞–Ω–¥–∞ ‚Üí [–≤—Ä–µ–º—è, –∞–≤—Ç–æ—Ä, –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—ã])
- –°–æ–±–∏—Ä–∞–µ—Ç –ø–æ—Å—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ —Ç–µ–ª–µ–≥—Ä–∞–º-–∫–∞–Ω–∞–ª
"""

import os
import sys
import re
import time
from html import escape
from urllib.parse import urljoin
from datetime import datetime, date
from zoneinfo import ZoneInfo

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
from bs4 import BeautifulSoup

# ------ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –æ–∫—Ä—É–∂–µ–Ω–∏—è ------
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "").strip()
CHAT_ID   = os.getenv("TELEGRAM_CHAT_ID", "").strip()

BASE = "https://www.sports.ru"
CALENDAR_URL = f"{BASE}/hockey/tournament/nhl/calendar/"

# ------ HTTP —Å —Ä–µ—Ç—Ä–∞—è–º–∏ ------
def make_session():
    s = requests.Session()
    retries = Retry(
        total=6, connect=6, read=6,
        backoff_factor=0.7,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["GET", "POST"],
        raise_on_status=False,
    )
    s.mount("https://", HTTPAdapter(max_retries=retries))
    s.headers.update({
        "User-Agent": "NHL-DailyResultsBot/1.3 (+sports.ru; Telegram)",
        "Accept-Language": "ru-RU,ru;q=0.9,en;q=0.6",
    })
    return s

S = make_session()

# ------ –≤—Å–ø–æ–º–æ–≥–∞–ª–∫–∏ ------
RU_MONTHS = {
    1: "—è–Ω–≤–∞—Ä—è", 2: "—Ñ–µ–≤—Ä–∞–ª—è", 3: "–º–∞—Ä—Ç–∞", 4: "–∞–ø—Ä–µ–ª—è",
    5: "–º–∞—è", 6: "–∏—é–Ω—è", 7: "–∏—é–ª—è", 8: "–∞–≤–≥—É—Å—Ç–∞",
    9: "—Å–µ–Ω—Ç—è–±—Ä—è", 10: "–æ–∫—Ç—è–±—Ä—è", 11: "–Ω–æ—è–±—Ä—è", 12: "–¥–µ–∫–∞–±—Ä—è",
}

def ru_date(d: date) -> str:
    return f"{d.day} {RU_MONTHS[d.month]}"

def ru_plural(n: int, forms: tuple[str, str, str]) -> str:
    # —Ñ–æ—Ä–º—ã: ("–º–∞—Ç—á", "–º–∞—Ç—á–∞", "–º–∞—Ç—á–µ–π")
    n = abs(n) % 100
    n1 = n % 10
    if 11 <= n <= 19: return forms[2]
    if 2 <= n1 <= 4:  return forms[1]
    if n1 == 1:      return forms[0]
    return forms[2]

TEAM_EMOJI = {
    "–ê–Ω–∞—Ö–∞–π–º": "ü¶Ü", "–ê—Ä–∏–∑–æ–Ω–∞": "ü§†", "–ë–æ—Å—Ç–æ–Ω": "üêª", "–ë–∞—Ñ—Ñ–∞–ª–æ": "ü¶¨",
    "–ö–∞–ª–≥–∞—Ä–∏": "üî•", "–ö–∞—Ä–æ–ª–∏–Ω–∞": "üå™Ô∏è", "–ö–æ–ª–æ—Ä–∞–¥–æ": "‚õ∞", "–ö–æ–ª–∞–º–±—É—Å": "üí£",
    "–î–∞–ª–ª–∞—Å": "‚≠ê", "–î–µ—Ç—Ä–æ–π—Ç": "üî¥", "–≠–¥–º–æ–Ω—Ç–æ–Ω": "üõ¢", "–§–ª–æ—Ä–∏–¥–∞": "üêÜ",
    "–õ–æ—Å-–ê–Ω–¥–∂–µ–ª–µ—Å": "üëë", "–ú–∏–Ω–Ω–µ—Å–æ—Ç–∞": "üå≤", "–ú–æ–Ω—Ä–µ–∞–ª—å": "üá®üá¶", "–ù—ç—à–≤–∏–ª–ª": "üêØ",
    "–ù—å—é-–î–∂–µ—Ä—Å–∏": "üòà", "–ê–π–ª–µ–Ω–¥–µ—Ä—Å": "üü†", "–†–µ–π–Ω–¥–∂–µ—Ä—Å": "üóΩ", "–û—Ç—Ç–∞–≤–∞": "üõ°",
    "–§–∏–ª–∞–¥–µ–ª—å—Ñ–∏—è": "üõ©", "–ü–∏—Ç—Ç—Å–±—É—Ä–≥": "üêß", "–°–∞–Ω-–•–æ—Å–µ": "ü¶à", "–°–∏—ç—Ç–ª": "ü¶ë",
    "–°–µ–Ω—Ç-–õ—É–∏—Å": "üéµ", "–¢–∞–º–ø–∞-–ë—ç–π": "‚ö°", "–¢–æ—Ä–æ–Ω—Ç–æ": "üçÅ", "–í–∞–Ω–∫—É–≤–µ—Ä": "üê≥",
    "–í–µ–≥–∞—Å": "üé∞", "–í–∞—à–∏–Ω–≥—Ç–æ–Ω": "ü¶Ö", "–í–∏–Ω–Ω–∏–ø–µ–≥": "‚úà", "–Æ—Ç–∞": "ü¶£",
    "–ß–∏–∫–∞–≥–æ": "ü¶Ö", "–ö–æ–ª–æ—Ä–∞–¥–æ –≠–≤–µ–ª–∞–Ω—á": "‚õ∞", "–õ–æ—Å-–ê–Ω–¥–∂–µ–ª–µ—Å –ö–∏–Ω–≥–∑": "üëë"
}

def emj(team: str) -> str:
    for k, v in TEAM_EMOJI.items():
        if k.lower() in team.lower():
            return v
    return "üèí"

def canonical_team_name(raw: str) -> str:
    """
    –ü—Ä–∏–≤–æ–¥–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã –∫ ¬´–∫–æ—Ä–æ—Ç–∫–æ–º—É¬ª –≤–∏–¥—É –∫–∞–∫ –≤ —Å–ª–æ–≤–∞—Ä–µ —ç–º–æ–¥–∑–∏.
    –ù–∞–ø—Ä–∏–º–µ—Ä, '–ù—å—é-–î–∂–µ—Ä—Å–∏ –î–µ–≤–∏–ª–∑' ‚Üí '–ù—å—é-–î–∂–µ—Ä—Å–∏'
    """
    raw_l = raw.lower()
    for short in TEAM_EMOJI.keys():
        if short.lower() in raw_l or raw_l in short.lower():
            return short
    # –∫–∞–∫ –µ—Å—Ç—å
    return raw.strip()

def get_london_today():
    return datetime.now(ZoneInfo("Europe/London")).date()

def log(*a):
    print(*a, file=sys.stderr)

# ------ –ø–∞—Ä—Å–∏–Ω–≥ –∫–∞–ª–µ–Ω–¥–∞—Ä—è –∑–∞ –Ω—É–∂–Ω—É—é –¥–∞—Ç—É ------
def fetch_calendar_html() -> str:
    r = S.get(CALENDAR_URL, timeout=30)
    r.raise_for_status()
    return r.text

def parse_calendar_for_date(html: str, target: date) -> list[dict]:
    """
    –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã, –≥–¥–µ –¥–∞—Ç–∞ == target –∏ —Å—á—ë—Ç —É–∂–µ –Ω–µ '- : -'
    –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ø–∏—Å–æ–∫: {home, away, score, match_url}
    """
    soup = BeautifulSoup(html, "html.parser")
    rows = soup.select("table tr")
    target_str = target.strftime("%d.%m.%Y")

    out = []
    for tr in rows:
        tds = tr.find_all("td")
        if len(tds) < 4:
            continue
        dt_text = " ".join(tds[0].get_text(" ", strip=True).split())
        if target_str not in dt_text:
            continue

        score_cell = tds[2]
        score_text = score_cell.get_text(" ", strip=True)
        if "- : -" in score_text or score_text.strip() in {"-:-", "- : -"}:
            continue

        a_score = score_cell.find("a")
        if not a_score or "/hockey/match/" not in (a_score.get("href") or ""):
            continue

        home_team = tds[1].get_text(" ", strip=True)
        away_team = tds[3].get_text(" ", strip=True)
        match_url = urljoin(BASE, a_score["href"])

        # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—á—ë—Ç
        score_text = re.sub(r"\s+", "", score_text)
        out.append({
            "home": canonical_team_name(home_team),
            "away": canonical_team_name(away_team),
            "score": score_text,   # 5:3, 4:5–æ—Ç, 2:3–± –∏ —Ç.–ø.
            "url": match_url
        })

    return out

# ------ –ø–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–∞—Ç—á–∞ (—É—Å—Ç–æ–π—á–∏–≤–∞—è –ª–µ–Ω—Ç–∞ –≥–æ–ª–æ–≤) ------
# –†–∞–∑–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –±—É–ª–ª–∏—Ç–æ–≤/–¥–µ—Ñ–∏—Å–æ–≤/–ø—Ä–æ–±–µ–ª–æ–≤, –∏–º—è –Ω–∞ –∫–∏—Ä–∏–ª–ª–∏—Ü–µ/–ª–∞—Ç–∏–Ω–∏—Ü–µ, –≤–æ–∑–º–æ–∂–Ω—ã –∞–ø–æ—Å—Ç—Ä–æ—Ñ—ã, –¥–µ—Ñ–∏—Å—ã –∏ —Ç.–¥.
NAME_CHARS = r"A-Za-z√Ä-√ø–ê-–Ø–∞-—è–Å—ë º‚Äô'`\-\. "
GOAL_LINE_RE = re.compile(
    rf"^[\s\-\‚Ä¢\*¬∑‚Äî‚Äì]*"                      # –±—É–ª–ª–∏—Ç/–¥–µ—Ñ–∏—Å/—Ç–∏—Ä–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
    rf"(?P<time>\d{{1,2}}(?::\d{{2}})?)"     # 10 –∏–ª–∏ 10:40
    rf"\s+"
    rf"(?P<scorer>[{NAME_CHARS}]+?)"         # —Ñ–∞–º–∏–ª–∏—è/–∏–º—è/–∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
    rf"(?:\s*\((?P<ast>[^)]*)\))?"           # –∞—Å—Å–∏—Å—Ç—ã –≤ —Å–∫–æ–±–∫–∞—Ö (–æ–ø—Ü.)
    rf"\s*$",
    re.M
)

def minute_from_timestr(timestr: str) -> int:
    timestr = timestr.strip()
    if ":" in timestr:
        m, _ = timestr.split(":", 1)
        return int(m)
    return int(timestr)

def detect_events_by_headers(full_text: str, home: str, away: str) -> list[dict]:
    """
    –ü–ª–∞–Ω A: –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —á–∞—Å—Ç–æ –µ—Å—Ç—å –¥–≤–∞ –±–ª–æ–∫–∞ –≤–∏–¥–∞:
        <–ù—å—é-–î–∂–µ—Ä—Å–∏>
          * 21 –•—ç–º–∏–ª—Ç–æ–Ω (–•–∏—à–∏—Ä, –ú–µ—Ä—Å–µ—Ä)
        <–°–∞–Ω-–•–æ—Å–µ>
          * 2 –≠–∫–ª—É–Ω–¥ (–°–µ–ª–µ–±—Ä–∏–Ω–∏)
    –ó–¥–µ—Å—å –º—ã —Å–∫–∞–Ω–∏—Ä—É–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –ø–æ—Å—Ç—Ä–æ—á–Ω–æ: –∫–æ–≥–¥–∞ –≤—Å—Ç—Ä–µ—á–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫,
    –ø–æ–º–µ—á–∞–µ–º current_team; –≤—Å–µ —Å—Ç—Ä–æ–∫–∏-–≥o–ª—ã –Ω–∏–∂–µ (–ø–æ regex) –æ—Ç–Ω–æ—Å–∏–º –∫ —ç—Ç–æ–π –∫–æ–º–∞–Ω–¥–µ
    –¥–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞.
    """
    known_headers = {home, away}
    events = []
    current = None

    for raw_line in full_text.splitlines():
        line = raw_line.strip()
        if not line:
            continue
        # –∑–∞–≥–æ–ª–æ–≤–æ–∫-–∫–æ–º–∞–Ω–¥–∞?
        if line in known_headers:
            current = line
            continue
        # –≥–æ–ª?
        m = GOAL_LINE_RE.match(line)
        if m and current in known_headers:
            t = m.group("time")
            scorer = " ".join((m.group("scorer") or "").split())
            assists = " ".join((m.group("ast") or "").split())
            events.append({
                "team": "home" if current == home else "away",
                "min": minute_from_timestr(t),
                "scorer": scorer,
                "assists": assists
            })

    return events

def detect_events_anywhere(full_text: str, home: str, away: str) -> list[dict]:
    """
    –ü–ª–∞–Ω B: –µ—Å–ª–∏ —è–≤–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –Ω–µ—Ç, –∏–¥—ë–º –ø–æ –≤—Å–µ–º—É —Ç–µ–∫—Å—Ç—É,
    –Ω–æ –≤ –∫–∞—á–µ—Å—Ç–≤–µ —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –≤—Å—Ç—Ä–µ—á–µ–Ω–Ω—ã–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–º–∞–Ω–¥.
    """
    possible_headers = set(TEAM_EMOJI.keys())
    events = []
    current = None

    for raw_line in full_text.splitlines():
        line = raw_line.strip()
        if not line:
            continue
        # –µ—Å–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å–æ–≤–ø–∞–ª–∞ —Å –ª—é–±—ã–º –∏–∑–≤–µ—Å—Ç–Ω—ã–º –∫–æ—Ä–æ—Ç–∫–∏–º –Ω–∞–∑–≤–∞–Ω–∏–µ–º ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º —Ç–µ–∫—É—â—É—é –∫–æ–º–∞–Ω–¥—É
        if line in possible_headers:
            # –Ω–æ —É—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –≤ —ç—Ç–æ–º –º–∞—Ç—á–µ
            if line == home or line == away:
                current = line
            continue
        m = GOAL_LINE_RE.match(line)
        if m and current in (home, away):
            t = m.group("time")
            scorer = " ".join((m.group("scorer") or "").split())
            assists = " ".join((m.group("ast") or "").split())
            events.append({
                "team": "home" if current == home else "away",
                "min": minute_from_timestr(t),
                "scorer": scorer,
                "assists": assists
            })
    return events

def parse_match_goals(match_url: str, home: str, away: str) -> list[dict]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –≥–æ–ª–æ–≤ —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –∫–æ–º–∞–Ω–¥–µ –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏–∏:
      [{"team":"home"/"away","min":int,"scorer":str,"assists":str}]
    """
    r = S.get(match_url, timeout=30)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")
    full_text = soup.get_text("\n")

    # 1) –ø—Ä–æ–±—É–µ–º —Å–∞–º—ã–π –Ω–∞–¥—ë–∂–Ω—ã–π –ø—É—Ç—å ‚Äî —è–≤–Ω—ã–µ –∑–∞–≥–æ–ª–æ–≤–∫–∏-–∫–æ–º–∞–Ω–¥—ã
    events = detect_events_by_headers(full_text, home, away)
    if events:
        events.sort(key=lambda x: x["min"])
        return events

    # 2) fallback ‚Äî –∏—Å–∫–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∏ —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –∏–∑–≤–µ—Å—Ç–Ω—ã—Ö –∫–æ—Ä–æ—Ç–∫–∏—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
    events = detect_events_anywhere(full_text, home, away)
    if events:
        events.sort(key=lambda x: x["min"])
        return events

    # 3) –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏ ‚Äî –≤–µ—Ä–Ω—ë–º –ø—É—Å—Ç–æ (–≤–µ—Ä—Ö–Ω–∏–π —É—Ä–æ–≤–µ–Ω—å –¥–æ–±–∞–≤–∏—Ç –∑–∞–≥–ª—É—à–∫—É)
    return []

# ------ —Å–±–æ—Ä–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è ------
def build_post(target_day: date) -> str:
    cal_html = fetch_calendar_html()
    matches = parse_calendar_for_date(cal_html, target_day)

    title = f"üóì –†–µ–≥—É–ª—è—Ä–Ω—ã–π —á–µ–º–ø–∏–æ–Ω–∞—Ç –ù–•–õ ‚Ä¢ {ru_date(target_day)} ‚Ä¢ {len(matches)} {ru_plural(len(matches), ('–º–∞—Ç—á', '–º–∞—Ç—á–∞', '–º–∞—Ç—á–µ–π'))}\n\n"
    title += "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞–¥—ë–∂–Ω–æ —Å–ø—Ä—è—Ç–∞–Ω—ã üëá\n\n‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî\n\n"

    chunks = [title]

    for i, m in enumerate(matches, 1):
        home, away, score = m["home"], m["away"], m["score"]

        # —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å—á—ë—Ç –ø–æ —á–∏—Å–ª–∞–º –¥–ª—è —à–∞–ø–∫–∏
        m_sc = re.match(r"^\s*(\d+)\s*:\s*(\d+)", score)
        hs, as_ = ("?", "?")
        if m_sc:
            hs, as_ = m_sc.group(1), m_sc.group(2)

        # –ª–µ–Ω—Ç–∞ –≥–æ–ª–æ–≤
        lines = []
        try:
            events = parse_match_goals(m["url"], home, away)
            h_go, a_go = 0, 0
            for ev in events:
                if ev["team"] == "home":
                    h_go += 1
                else:
                    a_go += 1
                # —Ñ–æ—Ä–º–∞—Ç: 0:1 ‚Äì 10 –ù–∞–∑–∞—Ä (–¢–µ—Ä—è–≤—è–π–Ω–µ–Ω, –ë–µ—Ä—Ç—É—Ü—Ü–∏)
                assists = f" ({ev['assists']})" if ev["assists"] else ""
                lines.append(f"{h_go}:{a_go} ‚Äì {ev['min']} {ev['scorer']}{assists}")
        except Exception as e:
            log(f"[WARN] goals parse failed for {home} vs {away}: {e}")

        if not lines:
            lines.append("‚Äî –ø–æ–¥—Ä–æ–±–Ω–∞—è –∑–∞–ø–∏—Å—å –≥–æ–ª–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")

        block = (
            f"{emj(home)} ¬´{home}¬ª: {hs}\n"
            f"{emj(away)} ¬´{away}¬ª: {as_}\n\n" +
            "\n".join(lines)
        )

        chunks.append(block.rstrip() + ("\n\n" if i < len(matches) else ""))

    return "".join(chunks).strip()

# ------ –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram (–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –ª–∏–º–∏—Ç–∞ 4096) ------
def tg_send(text: str):
    if not (BOT_TOKEN and CHAT_ID):
        raise RuntimeError("TELEGRAM_BOT_TOKEN / TELEGRAM_CHAT_ID –Ω–µ –∑–∞–¥–∞–Ω—ã")

    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
    # –¥–µ–ª–∏–º –ø–æ ~3500, —Å—Ç–∞—Ä–∞—è—Å—å —Ä–µ–∑–∞—Ç—å –ø–æ –ø—É—Å—Ç–æ–π —Å—Ç—Ä–æ–∫–µ
    MAX = 3500
    parts = []
    t = text
    while t:
        if len(t) <= MAX:
            parts.append(t)
            break
        cut = t.rfind("\n\n", 0, MAX)
        if cut == -1:
            cut = MAX
        parts.append(t[:cut])
        t = t[cut:].lstrip()

    for part in parts:
        resp = S.post(url, json={
            "chat_id": CHAT_ID,
            "text": part,
            "disable_web_page_preview": True,
        }, timeout=30)
        if resp.status_code != 200:
            raise RuntimeError(f"Telegram error {resp.status_code}: {resp.text}")
        time.sleep(0.6)

# ------ main ------
if __name__ == "__main__":
    try:
        # –ë–µ—Ä—ë–º –ø–æ –õ–æ–Ω–¥–æ–Ω—É ¬´—Å–µ–≥–æ–¥–Ω—è—à–Ω—é—é¬ª –¥–∞—Ç—É.
        # –ò–∑ –∫–∞–ª–µ–Ω–¥–∞—Ä—è –≤–∫–ª—é—á–∞–µ–º —Ç–æ–ª—å–∫–æ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ –º–∞—Ç—á–∏ (—Ç–∞–º —É–∂–µ –µ—Å—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å—á—ë—Ç).
        target = get_london_today()
        post = build_post(target)
        tg_send(post)
        print("OK")
    except Exception as e:
        print("ERROR:", repr(e), file=sys.stderr)
        sys.exit(1)
